[{"authors":null,"categories":null,"content":"I am a postdoctoral researcher at the International Audio Laboratories of the Fraunhofer Institute for Integrated Circuits (IIS). I specialize in spatial audio, multi-modal psychophysics, and data analysis. I like to work with virtual reality to sample and transform multi-modal sensory experiences to cognitive performance measures and quality judgments.\n","date":-62135596800,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":-62135596800,"objectID":"598b63dd58b43bce02403646f240cd3c","permalink":"https://rummukainen.github.io/author/admin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/admin/","section":"author","summary":"I am a postdoctoral researcher at the International Audio Laboratories of the Fraunhofer Institute for Integrated Circuits (IIS). I specialize in spatial audio, multi-modal psychophysics, and data analysis. I like to work with virtual reality to sample and transform multi-modal sensory experiences to cognitive performance measures and quality judgments.","tags":null,"title":"","type":"author"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":-62135596800,"objectID":"d41d8cd98f00b204e9800998ecf8427e","permalink":"https://rummukainen.github.io/author/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/","section":"author","summary":"","tags":null,"title":"Authors","type":"author"},{"authors":["Olli S. Rummukainen","Sebastian J. Schlecht","Thomas Robotham","Axel Plinge","Emanuël A. P. Habets"],"categories":null,"content":"","date":1553295600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1553295600,"objectID":"a55f4b2af4079283d0e8f6ea016c19e4","permalink":"https://rummukainen.github.io/publication/perceptual-study-of-near-field-binaural-audio-rendering-in-six-degrees-of-freedom-virtual-reality/","publishdate":"2019-03-23T00:00:00+01:00","relpermalink":"/publication/perceptual-study-of-near-field-binaural-audio-rendering-in-six-degrees-of-freedom-virtual-reality/","section":"publication","summary":"Auditory localization cues in the near-field (","tags":null,"title":"Perceptual Study of Near-Field Binaural Audio Rendering in Six-Degrees-of-Freedom Virtual Reality","type":"publication"},{"authors":["Olli S. Rummukainen","Sebastian J. Schlecht","Emanuël A. P. Habets"],"categories":null,"content":"","date":1540504800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1540504800,"objectID":"5e9eb007991dd099d6a9032acfb2aca7","permalink":"https://rummukainen.github.io/publication/self-translation-induced-minimum-audible-angle/","publishdate":"2018-10-26T00:00:00+02:00","relpermalink":"/publication/self-translation-induced-minimum-audible-angle/","section":"publication","summary":"The minimum audible angle has been studied with a stationary listener and a stationary or a moving sound source. The study at hand focuses on a scenario where the angle is induced by listener self-translation in relation to a stationary sound source. First, the classic stationary listener minimum audible angle experiment is replicated using a headphone-based reproduction system. This experiment confirms that the reproduction system is able to produce a localization cue resolution comparable to loudspeaker reproduction. Next, the self-translation minimum audible angle is shown to be 3.3° in the horizontal plane in front of the listener.","tags":null,"title":"Self-Translation Induced Minimum Audible Angle","type":"publication"},{"authors":["Thomas Robotham","Olli S. Rummukainen","Jürgen Herre","Emanuël A. P. Habets"],"categories":null,"content":"","date":1538863200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1538863200,"objectID":"d00d66b6fb19cd748c6b231897fe7640","permalink":"https://rummukainen.github.io/publication/evaluation-of-binaural-renderers-in-virtual-reality-environments-platform-and-examples/","publishdate":"2018-10-07T00:00:00+02:00","relpermalink":"/publication/evaluation-of-binaural-renderers-in-virtual-reality-environments-platform-and-examples/","section":"publication","summary":"One of the challenges of virtual reality technology is to provide convincing sensory information to users, to give the illusion of presence within the virtual environment. Audio-visual input combined with self-motion is a step beyond traditional cinematic content, whereby the audio renderer must accommodate a limitless number of potential user interactions and movements within an acoustic field. In this e-Brief, a framework for an online (real-time) 6 degrees-of-freedom evaluation platform is detailed. The platform allows psychoacoustic research and subjective testing of binaural audio renderers for virtual reality applications and finds application in the development of the MPEG-I Audio Standard.","tags":null,"title":"Evaluation of Binaural Renderers in Virtual Reality Environments: Platform and Examples","type":"publication"},{"authors":["Olli S. Rummukainen","Jing Wang","Zhitong Li","Thomas Robotham","Zhaoyu Yan","Zhuoran Li","Xiang Xie","Frederik Nagel","Emanuël A. P. Habets"],"categories":null,"content":"","date":1538863200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1538863200,"objectID":"8ad02c3077624ea715c462b37ab21162","permalink":"https://rummukainen.github.io/publication/influence-of-visual-content-on-the-perceived-audio-quality-in-virtual-reality/","publishdate":"2018-10-07T00:00:00+02:00","relpermalink":"/publication/influence-of-visual-content-on-the-perceived-audio-quality-in-virtual-reality/","section":"publication","summary":"To evoke a place illusion, virtual reality builds upon the integration of coherent sensory information from multiple modalities. This integrative view of perception could be contradicted when quality evaluation of virtual reality is divided into multiple uni-modal tests. We show the type and cross-modal consistency of visual content to affect overall audio quality in a six-degrees-of-freedom virtual environment with expert and naïve participants. The effect is observed both in their movement patterns and direct quality scores given to three real-time binaural audio rendering technologies. Our experiments show that the visual content has a statistically significant effect on the perceived audio quality.","tags":null,"title":"Influence of Visual Content on the Perceived Audio Quality in Virtual Reality","type":"publication"},{"authors":["Thomas Robotham","Olli S. Rummukainen","Jürgen Herre","Emanuël A. P. Habets"],"categories":null,"content":"","date":1538863200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1538863200,"objectID":"5a98f03818a9af0dc495208e8ea4cfd2","permalink":"https://rummukainen.github.io/publication/online-vs-offline-multiple-stimulus-audio-quality-evaluation-for-virtual-reality/","publishdate":"2018-10-07T00:00:00+02:00","relpermalink":"/publication/online-vs-offline-multiple-stimulus-audio-quality-evaluation-for-virtual-reality/","section":"publication","summary":"Virtual reality technology incorporating six degrees-of-freedom introduces new challenges for the evaluation of audio quality. Here, a real-time “online” evaluation platform is proposed, allowing multiple stimulus comparison of binaural renderers within the virtual environment, to perceptually evaluate audio quality. To evaluate the sensitivity of the platform, tests were conducted using the online platform with audiovisual content, and two traditional platforms with pre-rendered “off-line” audiovisual content. Conditions employed had known relative levels of impairments. A comparison of the results across platforms indicates that only the proposed online platform produced results representative of the known impaired audio conditions. Off-line platforms were found to be not sufficient in detecting the tested impairments for audio as part of a multi-modal virtual reality environment.","tags":null,"title":"Online vs. Offline Multiple Stimulus Audio Quality Evaluation for Virtual Reality","type":"publication"},{"authors":["Olli S. Rummukainen","Thomas Robotham","Sebastian J. Schlecht","Axel Plinge","Jürgen Herre","Emanuël A. P. Habets"],"categories":null,"content":"","date":1533938400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1533938400,"objectID":"130ac46d1cb94ce1c916ea05039352ee","permalink":"https://rummukainen.github.io/publication/audio-quality-evaluation-in-virtual-reality-multiple-stimulus-ranking-with-behavior-tracking/","publishdate":"2018-08-11T00:00:00+02:00","relpermalink":"/publication/audio-quality-evaluation-in-virtual-reality-multiple-stimulus-ranking-with-behavior-tracking/","section":"publication","summary":"Virtual reality systems with multimodal stimulation and up to six degrees-of-freedom movement pose novel challenges to audio quality evaluation. This paper adapts classic multiple stimulus test methodology to virtual reality and adds behavioral tracking functionality. The method is based on ranking by elimination while exploring an audiovisual virtual reality. The proposed evaluation method allows immersion in multimodal virtual scenes while enabling comparative evaluation of multiple binaural renderers. A pilot study is conducted to evaluate feasibility of the proposed method and to identify challenges in virtual reality audio quality evaluation. Finally, the results are compared to a non-immersive off-line evaluation method.","tags":null,"title":"Audio Quality Evaluation in Virtual Reality: Multiple Stimulus Ranking with Behavior Tracking","type":"publication"},{"authors":["Axel Plinge","Sebastian J. Schlecht","Oliver Thiergart","Thomas Robotham","Olli S. Rummukainen","Emanuël A. P. Habets"],"categories":null,"content":"","date":1533938400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1533938400,"objectID":"584ded2cf77795ebf5fc71160a754282","permalink":"https://rummukainen.github.io/publication/six-degrees-of-freedom-binaural-audio-reproduction-of-first-order-ambisonics-with-distance-information/","publishdate":"2018-08-11T00:00:00+02:00","relpermalink":"/publication/six-degrees-of-freedom-binaural-audio-reproduction-of-first-order-ambisonics-with-distance-information/","section":"publication","summary":"First-order Ambisonics (FOA) recordings can be processed and reproduced over headphones. They can be rotated to account for the listener’s head orientation. However, virtual reality (VR) systems allow the listener to move in six-degrees-of-freedom (6DoF), ie, three rotational plus three transitional degrees of freedom. Here, the apparent angles and distances of the sound sources depend on the listener’s position. We propose a technique to facilitate 6DoF. In particular, a FOA recording is described using a parametric model, which is modified based on the listener’s position and information about the distances to the sources. We evaluate our method by a listening test, comparing different binaural renderings of a synthetic sound scene in which the listener can move freely.","tags":null,"title":"Six-Degrees-of-Freedom Binaural Audio Reproduction of First-Order Ambisonics with Distance Information","type":"publication"},{"authors":["Olli S. Rummukainen","Sebastian J. Schlecht","Axel Plinge","Emanuël A. P. Habets"],"categories":null,"content":"","date":1507413600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1507413600,"objectID":"4d4722c1c9051b56e769fcb375ef1d6c","permalink":"https://rummukainen.github.io/publication/evaluating-binaural-reproduction-systems-from-behavioral-patterns-in-a-virtual-reality-a-case-study-with-impaired-binaural-cues-and-tracking-latency/","publishdate":"2017-10-08T00:00:00+02:00","relpermalink":"/publication/evaluating-binaural-reproduction-systems-from-behavioral-patterns-in-a-virtual-reality-a-case-study-with-impaired-binaural-cues-and-tracking-latency/","section":"publication","summary":"This paper proposes a method for evaluating real-time binaural reproduction systems by means of a wayfinding task in six degrees of freedom. Participants physically walk to sound objects in a virtual reality created by a head-mounted display and binaural audio. The method allows for comparative evaluation of different rendering and tracking systems. We show how the localization accuracy of spatial audio rendering is reflected by objective measures of the participants’ behavior and task performance. As independent variables we add tracking latency or reduce the binaural cues. We provide a reference scenario with loudspeaker reproduction and an anchor scenario with monaural reproduction for comparison.","tags":null,"title":"Evaluating Binaural Reproduction Systems from Behavioral Patterns in a Virtual Reality—A Case Study with Impaired Binaural Cues and Tracking Latency","type":"publication"},{"authors":["Olli S. Rummukainen","Sebastian J. Schlecht","Axel Plinge","Emanuël A. P. Habets"],"categories":null,"content":"","date":1496095200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1496095200,"objectID":"976f43605308118cc33adec6f876b1a5","permalink":"https://rummukainen.github.io/publication/evaluation-of-binaural-reproduction-systems-from-behavioral-patterns-in-a-six-degrees-of-freedom-wayfinding-task/","publishdate":"2017-05-30T00:00:00+02:00","relpermalink":"/publication/evaluation-of-binaural-reproduction-systems-from-behavioral-patterns-in-a-six-degrees-of-freedom-wayfinding-task/","section":"publication","summary":"This paper proposes a new method for evaluating real-time binaural reproduction systems by means of a wayfinding task in six degrees of freedom. Participants physically walk to sound objects in a virtual reality created by a head-mounted display and binaural audio. We show how the localization accuracy of spatial audio rendering is reflected by objective measures of the participants' behavior. The method allows for comparative evaluation of different rendering systems as well as the subjective assessment of the quality of experience.","tags":null,"title":"Evaluation of Binaural Reproduction Systems from Behavioral Patterns in a Six-Degrees-of-Freedom Wayfinding Task","type":"publication"},{"authors":["Olli S. Rummukainen"],"categories":null,"content":"","date":1481583600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1481583600,"objectID":"5ded0ac71fbe8898b135722690955fee","permalink":"https://rummukainen.github.io/publication/reproducing-reality-perception-and-quality-in-immersive-audiovisual-environments/","publishdate":"2016-12-13T00:00:00+01:00","relpermalink":"/publication/reproducing-reality-perception-and-quality-in-immersive-audiovisual-environments/","section":"publication","summary":"The research in this thesis may be classified into two inter-related categories: understanding human perceptual information processing under natural audiovisual conditions and, based on this knowledge, evaluating the quality of experience and content perception in immersive audiovisual reproductions. The main concept guiding this work is the observation that there is no need to simulate the whole world if it cannot be perceived. The three main findings in the first category are: 1) The most important perceptual attributes in natural scenes depicting urban environments were found to be the amount of movement, perceived noisiness, and openness of the scene. 2) Movement and openness were found to be mainly visual attributes. In some scenes, the auditory system was able to derive information about movement and openness that was comparable with audiovisual conditions already after 500 ms stimulation. Noisiness was dominantly auditory, but visual information was found to be an aiding factor. Cross-modality effects affecting global estimates of the scene attributes were found in movement and openness. 3) Task-relevant auditory cues were found to aid in orienting to and detecting a peripheral but not a central visual target. Significant improvements were found with a 1000 ms audio lead compared to synchronous onset, and with a 500 ms audio lead compared to no sound condition. The main findings in the second category are: 1) The spatial extent of the reproduction setup affects the perception of natural scene attributes especially in movement, where discrimination accuracy decreases with larger reproduction extent, and in noisiness, where the discrimination accuracy increases. 2) With full video width the effect of the spatial width of audio on quality of experience is the strongest, but as the video width is reduced, the effect of audio width almost disappears. 3) Immersive 3D sound is able to hinder the perception of visual events in video reproduction by dispersing visual attention. 4) In 2D video combined with 3D spatial sound the perceived spatial discrepancy between the auditory and visual events may become annoying if the observer is seated close to the screen and off-axis.","tags":null,"title":"Reproducing Reality: Perception and Quality in Immersive Audiovisual Environments","type":"publication"},{"authors":["Olli S. Rummukainen","Catarina Mendonça"],"categories":null,"content":"","date":1472076000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1472076000,"objectID":"3652b8ae692b7861b53772f39e88213b","permalink":"https://rummukainen.github.io/publication/reproducing-reality-multimodal-contributions-in-natural-scene-discrimination/","publishdate":"2016-08-25T00:00:00+02:00","relpermalink":"/publication/reproducing-reality-multimodal-contributions-in-natural-scene-discrimination/","section":"publication","summary":"Most research on multisensory processing focuses on impoverished stimuli and simple tasks. In consequence, very little is known about the sensory contributions in the perception of real environments. Here, we presented 23 participants with paired comparison tasks, where natural scenes were discriminated in three perceptually meaningful attributes: movement, openness, and noisiness. The goal was to assess the auditory and visual modality contributions in scene discrimination with short (≤500ms) natural scene exposures. The scenes were reproduced in an immersive audiovisual environment with 3D sound and surrounding visuals. Movement and openness were found to be mainly visual attributes with some input from auditory information. In some scenes, the auditory system was able to derive information about movement and openness that was comparable with audiovisual condition already after 500ms stimulation. Noisiness was mainly auditory, but visual information was found to have a facilitatory role in a few scenes. The sensory weights were highly imbalanced in favor of the stronger modality, but the weaker modality was able to affect the bimodal estimate in some scenes.","tags":null,"title":"Reproducing reality: Multimodal contributions in natural scene discrimination","type":"publication"},{"authors":["Olli S. Rummukainen","David Romblom","Catherine Guastavino"],"categories":null,"content":"","date":1461189600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461189600,"objectID":"41586ef0e8038bcb0bcfbc9b2044237f","permalink":"https://rummukainen.github.io/publication/diffuse-field-modeling-using-physically-inspired-decorrelation-filters-and-b-format-microphones-part-ii-evaluation/","publishdate":"2016-04-21T00:00:00+02:00","relpermalink":"/publication/diffuse-field-modeling-using-physically-inspired-decorrelation-filters-and-b-format-microphones-part-ii-evaluation/","section":"publication","summary":"The Diffuse Field Model (DFM) described in Part 1 is perceptually evaluated in this article. Two experiments were conducted. In first experiment, sound recording professionals rated different treatments of DFM presented on a 20-channel array. This evaluation included the geometric modeling of reflections, strategies involving the early portion of the B-Format Room Impulse Response (RIR), and a comparison between 0th- and 1st-order RIR. Results indicate that it is necessary to model the earliest reflections and to use all four channels of the B-Format room impulse response. In the second experiment, musicians and sound recording professionals were asked to rate DFM and common microphone techniques presented on 3/2 stereophonic setup. DFM was found to be perceptually comparable to the Hamasaki Square technique. DFM approach used in this study is part of a physically-plausible virtual acoustic model for sources that were captured with close microphone placement. This model replaces the panning, delay, and reverberation that would typically be used. DFM is a perceptually viable method to create room impression that allows free placement of anechoic point sources in arbitrary multichannel loudspeaker setups.","tags":null,"title":"Diffuse Field Modeling Using Physically-Inspired Decorrelation Filters and B-Format Microphones: Part II Evaluation","type":"publication"},{"authors":["Mikko Nuutinen","Toni Virtanen","Olli S. Rummukainen","Jukka Häkkinen"],"categories":null,"content":"","date":1456786800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1456786800,"objectID":"3da4a945eaa36a24425fd8db039ce5e7","permalink":"https://rummukainen.github.io/publication/vqone-matlab-toolbox-a-graphical-experiment-builder-for-image-and-video-quality-evaluations/","publishdate":"2016-03-01T00:00:00+01:00","relpermalink":"/publication/vqone-matlab-toolbox-a-graphical-experiment-builder-for-image-and-video-quality-evaluations/","section":"publication","summary":"This article presents VQone, a graphical experiment builder, written as a MATLAB toolbox, developed for image and video quality ratings. VQone contains the main elements needed for the subjective image and video quality rating process. This includes building and conducting experiments and data analysis. All functions can be controlled through graphical user interfaces. The experiment builder includes many standardized image and video quality rating methods. Moreover, it enables the creation of new methods or modified versions from standard methods. VQone is distributed free of charge under the terms of the GNU general public license and allows code modifications to be made so that the program’s functions can be adjusted according to a user’s requirements. VQone is available for download from the project page (http://www.helsinki.fi/psychology/groups/visualcognition/).","tags":null,"title":"VQone MATLAB toolbox: A graphical experiment builder for image and video quality evaluations","type":"publication"},{"authors":["Olli S. Rummukainen","Catarina Mendonça"],"categories":null,"content":"","date":1453762800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1453762800,"objectID":"a619b89e34d4b477784b4c8bb98d8ac6","permalink":"https://rummukainen.github.io/publication/task-relevant-spatialized-auditory-cues-enhance-attention-orientation-and-peripheral-target-detection-in-natural-scenes/","publishdate":"2016-01-26T00:00:00+01:00","relpermalink":"/publication/task-relevant-spatialized-auditory-cues-enhance-attention-orientation-and-peripheral-target-detection-in-natural-scenes/","section":"publication","summary":"Concurrent auditory stimuli have been shown to enhance detection of abstract visual targets in experimental setups with little ecological validity. We presented 11 participants, wearing an eye-tracking device, with a visual detection task in an immersive audiovisual environment replicating a real-world environment. The participants were to fixate on a visual target and to press a key when they were confident of having detected the target. The visual world was accompanied by a task-relevant or task-irrelevant spatialized sound scene with different onset asynchronies. Our findings indicate task-relevant auditory cues to aid in orienting to and detecting a peripheral but not central visual target. The enhancement is amplified with an increasing amount of audio lead.","tags":null,"title":"Task-Relevant Spatialized Auditory Cues Enhance Attention Orientation and Peripheral Target Detection in Natural Scenes","type":"publication"},{"authors":["Catarina Mendonça","Olli S. Rummukainen","Ville Pulkki"],"categories":null,"content":"","date":1435701600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1435701600,"objectID":"47a6ea4de1610a5cad71755f54ad97a7","permalink":"https://rummukainen.github.io/publication/3d-sound-can-have-a-negative-impact-on-the-perception-of-visual-content-in-audiovisual-reproductions/","publishdate":"2015-07-01T00:00:00+02:00","relpermalink":"/publication/3d-sound-can-have-a-negative-impact-on-the-perception-of-visual-content-in-audiovisual-reproductions/","section":"publication","summary":"There is reason to believe that sound interacts with visual attention mechanisms. Practical implications of that interaction have never been analyzed in the context of spatial sound design for audiovisual reproduction. The study reported here aimed to test if sound spatialization could affect eye movements and the processing of visual events in audiovisual scenes. We presented participants with audiovisual scenes of a metro station. The sound was either mono, stereo, or 3D. Participants wore eye tracking glasses during the experiment and their task was to count how many people entered the metro. In the divided attention task, participants had to count people entering 3 doors of the metro. In the selective attention task, participants had to count how many people entered the middle door alone. It was found that sound spatialization did not affect the divided attention task. But in the selective attention task participants counted less visual events with 3D sound. In that condition, the number of eye fixations and time spent in the visual area of interest were smaller. It is hypothesized that, in the case of divided attention, the attention is already disengaged and fluctuating, which could explain why sound did not have any additional effect. In the selective attention task, participants must remain concentrated in only one visual area and competing well-spatialized sounds in peripheral areas might have a negative impact. These results should be taken into consideration when designing sound spatialization algorithms and soundtracks.","tags":null,"title":"3D Sound Can Have a Negative Impact on the Perception of Visual Content in Audiovisual Reproductions","type":"publication"},{"authors":["Olli S. Rummukainen","Catarina Mendonça"],"categories":null,"content":"","date":1410991200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1410991200,"objectID":"b00863a690251b2c5e4e937a03a49fc7","permalink":"https://rummukainen.github.io/publication/content-or-reproduction-natural-scene-perception-in-immersive-and-non-immersive-reproduction-setups/","publishdate":"2014-09-18T00:00:00+02:00","relpermalink":"/publication/content-or-reproduction-natural-scene-perception-in-immersive-and-non-immersive-reproduction-setups/","section":"publication","summary":"In this work the effect of reproduction setup on the perception of natural scene attributes was studied. Discrimination of reproduced real-world scenes in movement, openness and noisiness was inspected between an immersive large reproduction setup and a non-immersive small reproduction setup. The results show decreased sensitivity for movement discrimination and increased sensitivity for noisiness discrimination when using the large setup, and content dependent effects for openness discrimination. The results have implications on future content descriptors and quality evaluation in large-screen systems and spatial audio setups.","tags":null,"title":"Content or Reproduction: Natural Scene Perception in Immersive and Non-Immersive Reproduction Setups","type":"publication"},{"authors":["Olli S. Rummukainen","Catarina Mendonça","Ville Pulkki"],"categories":null,"content":"","date":1409522400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1409522400,"objectID":"9b27633723ae9f3c71883ccaa4fc653f","permalink":"https://rummukainen.github.io/publication/perceptual-attributes-of-natural-dynamic-audiovisual-scenes/","publishdate":"2014-09-01T00:00:00+02:00","relpermalink":"/publication/perceptual-attributes-of-natural-dynamic-audiovisual-scenes/","section":"publication","summary":"This work analyzed the perceptual attributes of natural dynamic audiovisual scenes in two consecutive experiments. First, we presented 30 naive participants with 19 natural scenes depicting urban environments reproduced with an immersive audiovisual display utilizing surrounding visual projections and spatial audio reproduction. The aim was to assess the perceptual dimensionality of natural scenes, and to identify significant perceptual attributes by means of a similarity categorization task and an interview. A two-dimensional perceptual map of the stimulus scenes and perceptual attributes was formed, and the exploratory results show the amount of movement and perceived noisiness of the scene to be the most important perceptual attributes in naturalistically reproduced real-world urban environments. We found the scene gist properties openness and expansion to remain as important factors in scenes with no salient auditory or visual events. Our second experiment was organized with 23 naive participants to assess the modality contributions in three salient perceptual attributes through pairwise unimodal and bimodal scene discrimination tasks with short (","tags":null,"title":"Perceptual Attributes of Natural Dynamic Audiovisual Scenes","type":"publication"},{"authors":["Olli S. Rummukainen","Jenni Radun","Toni Virtanen","Ville Pulkki"],"categories":null,"content":"","date":1398895200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1398895200,"objectID":"5bdc260efa7a397b2c2a8e4c24b8411f","permalink":"https://rummukainen.github.io/publication/categorization-of-natural-dynamic-audiovisual-scenes/","publishdate":"2014-05-01T00:00:00+02:00","relpermalink":"/publication/categorization-of-natural-dynamic-audiovisual-scenes/","section":"publication","summary":"This work analyzed the perceptual attributes of natural dynamic audiovisual scenes. We presented thirty participants with 19 natural scenes in a similarity categorization task, followed by a semi-structured interview. The scenes were reproduced with an immersive audiovisual display. Natural scene perception has been studied mainly with unimodal settings, which have identified motion as one of the most salient attributes related to visual scenes, and sound intensity along with pitch trajectories related to auditory scenes. However, controlled laboratory experiments with natural multimodal stimuli are still scarce. Our results show that humans pay attention to similar perceptual attributes in natural scenes, and a two-dimensional perceptual map of the stimulus scenes and perceptual attributes was obtained in this work. The exploratory results show the amount of movement, perceived noisiness, and eventfulness of the scene to be the most important perceptual attributes in naturalistically reproduced real-world urban environments. We found the scene gist properties openness and expansion to remain as important factors in scenes with no salient auditory or visual events. We propose that the study of scene perception should move forward to understand better the processes behind multimodal scene processing in real-world environments. We publish our stimulus scenes as spherical video recordings and sound field recordings in a publicly available database.","tags":null,"title":"Categorization of Natural Dynamic Audiovisual Scenes","type":"publication"},{"authors":["Olli S. Rummukainen","Ville Pulkki"],"categories":null,"content":"","date":1372802400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1372802400,"objectID":"9972057439ea368d513786aac815f975","permalink":"https://rummukainen.github.io/publication/audiovisual-reproduction-in-surrounding-display-effect-of-spatial-width-of-audio-and-video/","publishdate":"2013-07-03T00:00:00+02:00","relpermalink":"/publication/audiovisual-reproduction-in-surrounding-display-effect-of-spatial-width-of-audio-and-video/","section":"publication","summary":"Current perception-based quality metrics for unimodal systems cannot reflect the perceived quality in multimodal situations, and better understanding of multimodal perceptual mechanisms is needed. In this work, audiovisual perception was studied with an immersive audiovisual display. The aim was to observe cross-modal interaction of auditory and visual modalities, when the spatial width of audio and video reproduction were limited and overall perceived degradation evaluated. The results show both audio and video width affect the perceived degradation of a stimulus. The effect of audio width decreases as video width is decreased. Constrained correspondence analysis suggests the reasons for highest perceived degradation to be wrong audio direction, reduced video width and missing essential content.","tags":null,"title":"Audiovisual Reproduction in Surrounding Display: Effect of Spatial Width of Audio and Video","type":"publication"},{"authors":["Olli S. Rummukainen","Javier Gómez Bolaños","Ville Pulkki"],"categories":null,"content":"","date":1372802400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1372802400,"objectID":"342fbbe1b28afcec41d230bc825285de","permalink":"https://rummukainen.github.io/publication/horizontal-localization-of-auditory-and-visual-events-with-directional-audio-coding-and-2d-video/","publishdate":"2013-07-03T00:00:00+02:00","relpermalink":"/publication/horizontal-localization-of-auditory-and-visual-events-with-directional-audio-coding-and-2d-video/","section":"publication","summary":"The effects of using two-dimensional video projection together with parametric three-dimensional spatial audio reproduction system are examined in this study. The discrepancy between the auditory and visual events, and differing depth cues, are evaluated by means of subjective evaluations using the method of adjustment. The results show the Directional Audio Coding to be well suited for immersive audiovisual setups allowing a large area of viewing positions.","tags":null,"title":"Horizontal Localization of Auditory and Visual Events with Directional Audio Coding and 2D Video","type":"publication"},{"authors":["Olli S. Rummukainen"],"categories":null,"content":"","date":1325286000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1325286000,"objectID":"356e0b8595f2954920fae10069c7c39a","permalink":"https://rummukainen.github.io/publication/audiovisual-reproduction-in-surrounding-display-effect-of-spatial-width-of-audio-and-video_thesis/","publishdate":"2011-12-31T00:00:00+01:00","relpermalink":"/publication/audiovisual-reproduction-in-surrounding-display-effect-of-spatial-width-of-audio-and-video_thesis/","section":"publication","summary":"Multimodal perception strives to integrate information from multiple sensorial channels into a unified experience, that contains more information than just the sum of the separate unimodal percepts. As a result, traditional quality metrics for unimodal services cannot reflect the perceived quality in multimodal situations, and new quality estimation methods are needed. In this work, audiovisual perception was studied with an immersive audiovisual display. The audiovisual display consisted of a video screen with field of view of 226 and 3D sound reproduction with 20 loudspeakers. The aim of the study was to observe the crossmodal interaction of auditory and visual modalities, when the spatial widths of audio and video reproduction were limited. A subjective study was organized, where the overall perceived degradation of the stimuli was evaluated with Degradation Category Rating in four different types of audiovisual content. In addition, free descriptions of the most prominent degrading factors were collected. The participants' individual tendencies to experience immersion were screened prior to the experiment with a questionnaire. The results show that video width is the dominant element in defining the degradation of a stimulus. Also audio width had an impact when the video width was at maximum. Individual tendency to experience immersion was not found to have significant impact on perceived degradation in this study. Slight content effects were observed. Constrained correspondence analysis of the free description data suggests the reasons for highest perceived degradation to be caused by wrong audio direction, reduced video width and missing essential content.","tags":null,"title":"Audiovisual Reproduction in Surrounding Display: Effect of Spatial Width of Audio and Video","type":"publication"}]